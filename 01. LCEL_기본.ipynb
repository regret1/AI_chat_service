{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpXAYwWtvPJc"
      },
      "source": [
        "## LangChain Expression Language(LCEL)\n",
        "\n",
        "https://python.langchain.com/v0.1/docs/expression_language/why/\n",
        "\n",
        "### 기본 구조: 프롬프트 + 모델 + 출력 파서\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIoYCh-L1JnU",
        "outputId": "2ad2db1c-8119-4ab2-86cc-82392a63e330"
      },
      "outputs": [],
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install -Uq python-dotenv langchain_teddynote langchain_openai langchain langchain-community faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnCOW0AjvPJd",
        "outputId": "a37f3c44-83bd-48f5-c76a-c9b4678f9656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# API KEY 정보로드\n",
        "load_dotenv(\"../content/.env\", override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiMzpTivvPJe",
        "outputId": "b0b98513-f76d-4fb4-b478-5c08016c5691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LANGCHAIN_PROJECT]\n",
            "LCEL\n"
          ]
        }
      ],
      "source": [
        "#API KEY 저장을 위한 os 라이브러리 호출\n",
        "import os\n",
        "\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LCEL'\n",
        "print(f\"[LANGCHAIN_PROJECT]\\n{os.environ['LANGCHAIN_PROJECT']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVaNJoQrvPJe",
        "outputId": "5a2873fd-695b-45e4-945d-97d665da7751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain/LangSmith API Key가 설정되지 않았습니다. 참고: https://wikidocs.net/250954\n"
          ]
        }
      ],
      "source": [
        "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
        "# !pip install -qU langchain-teddynote\n",
        "from langchain_teddynote import logging\n",
        "\n",
        "# 프로젝트 이름을 입력합니다.\n",
        "logging.langsmith(\"LCEL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ewT0hDevPJf"
      },
      "source": [
        "### 프롬프트 템플릿의 활용\n",
        "\n",
        "`PromptTemplate`\n",
        "\n",
        "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿\n",
        "  - `template`: 템플릿 문자열. 문자열 내에서 중괄호 `{}`는 변수를 나타냄\n",
        "  - `input_variables`: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의함\n",
        "\n",
        "`input_variables`\n",
        "\n",
        "- input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kI_FH_tHvPJf"
      },
      "outputs": [],
      "source": [
        "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9J37IJ7vPJf"
      },
      "source": [
        "`from_template()` 메소드를 사용하여 PromptTemplate 객체 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcSxhxykvPJf",
        "outputId": "4bd1036a-6fda-444f-dad8-38ae65157bef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# template 정의\n",
        "template = \"{country}의 수도는 어디인가요?\"\n",
        "\n",
        "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
        "prompt_template = PromptTemplate.from_template(template)\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9SH-ZjhgvPJf",
        "outputId": "3cf7aced-3f2f-4854-faf6-3d8c5f567785"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'대한민국의 수도는 어디인가요?'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt 생성\n",
        "prompt = prompt_template.format(country=\"대한민국\")\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NntrduzZvPJf",
        "outputId": "c80255d9-d8a8-4bec-f327-90bb750b48a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'미국의 수도는 어디인가요?'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt 생성\n",
        "prompt = prompt_template.format(country=\"미국\")\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Ym_PZOR7vPJf"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    max_tokens=2048,\n",
        "    temperature=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [실습] 셰프 프롬프트 템플릿 만들기\n",
        "\n",
        "1. 변수 `food`에 음식 식재료를 입력받기 \n",
        "2. `food` 재료로 만들 수 있는 음식 메뉴를 추천해주는 프롬프트 템플릿 객체 `chef_prompt` 생성하기\n",
        "3. `food` 변수에 재료(값)를 넣어서 프롬프트를 완성해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='토마토는 다양한 요리에 활용할 수 있는 재료입니다. 아래는 토마토로 만들 수 있는 몇 가지 음식 메뉴를 추천드립니다:\\n\\n1. **토마토 파스타**: 신선한 토마토 소스를 만들어 파스타와 함께 볶아내면 간단하면서도 맛있는 요리가 됩니다.\\n\\n2. **토마토 샐러드**: 신선한 토마토, 모짜렐라 치즈, 바질을 곁들여 올리브 오일과 발사믹 식초로 드레싱한 샐러드입니다.\\n\\n3. **토마토 수프**: 토마토를 갈아서 만든 수프로, 크림을 추가하면 더욱 부드럽고 풍미가 깊어집니다.\\n\\n4. **토마토 브루스케타**: 다진 토마토, 마늘, 바질을 섞어 바삭한 빵 위에 올려서 간단한 전채 요리로 즐길 수 있습니다.\\n\\n5. **토마토 리조또**: 토마토와 쌀을 함께 조리하여 만든 리조또로, 풍부한 맛을 느낄 수 있습니다.\\n\\n6. **토마토 오믈렛**: 계란과 함께 토마토를 넣어 만든 오믈렛으로, 아침 식사로 좋습니다.\\n\\n7. **토마토 피자**: 토마토 소스를 바른 피자 도우 위에 다양한 토핑을 올려 구워내면 맛있는 피자가 완성됩니다.\\n\\n8. **토마토 카레**: 토마토를 베이스로 한 카레로, 다양한 채소와 함께 조리하면 건강한 한 끼가 됩니다.\\n\\n이 외에도 토마토는 다양한 요리에 활용할 수 있으니, 창의력을 발휘해 보세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 396, 'prompt_tokens': 19, 'total_tokens': 415, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CJrB7n3jP5s2qZI52LreZHsFV6KCS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b8229c4d-7596-4f21-a7af-b06c2cf4f00e-0', usage_metadata={'input_tokens': 19, 'output_tokens': 396, 'total_tokens': 415, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 실습 코드 작성\n",
        "# template 정의\n",
        "template = \"{food}로 만들 수 있는 음식 메뉴를 추천해주세요\"\n",
        "\n",
        "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
        "chef_prompt = PromptTemplate.from_template(template)\n",
        "chef_prompt\n",
        "\n",
        "prompt = chef_prompt.format(food=\"토마토\")\n",
        "\n",
        "model.invoke(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B30oVFVFvPJg"
      },
      "source": [
        "### Chain 생성\n",
        "\n",
        "#### LCEL(LangChain Expression Language)\n",
        "\n",
        "\n",
        "```\n",
        "chain = prompt | model | output_parser\n",
        "```\n",
        "\n",
        "이 체인에서 사용자 입력은 프롬프트 템플릿으로 전달되고, 그런 다음 프롬프트 템플릿 출력은 모델로 전달\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oANeCLI_vPJg",
        "outputId": "bc61d7ad-9438-48c7-90d7-826d0963e267"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='{topic} 에 대해 쉽게 설명해주세요.')\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D1FE26F250>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D1FE26F610>, root_client=<openai.OpenAI object at 0x000001D1FE26EFD0>, root_async_client=<openai.AsyncOpenAI object at 0x000001D1FE26F390>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "chain = prompt | model\n",
        "chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [실습] 셰프 챗봇을 위한 openAI 모델 생성\n",
        "\n",
        "1. 변수 `chef_model` 선언하기\n",
        "2. 사용할 모델은 `gpt-4o-mini` 지정\n",
        "3. 창의성을 조절하는 변수는 `0.1` 로 지정\n",
        "4. 최대 활용할 토큰은 `4096`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 실습 코드 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [실습] 셰프 챗봇을 위한 chef_chain 생성\n",
        "\n",
        "- 프롬프트 템플릿 변수 `chef_prompt` 와 llm 모델을 담은 `chef_model` 모델을 체인(`|`)으로 연결하여 `chef_chain` 변수 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 실습 코드 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX2wyZckvPJg"
      },
      "source": [
        "### invoke() 호출\n",
        "\n",
        "- python 딕셔너리 형태(키: 값)로 입력값을 전달\n",
        "- invoke() 함수 호출 시, 입력값을 전달"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZQmyvp1ivPJg"
      },
      "outputs": [],
      "source": [
        "# input 딕셔너리에 주제 설정\n",
        "input = {\"topic\": \"인공지능의 학습 방법\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N9RCGgVvPJg",
        "outputId": "9f3fe17e-9219-497e-e7a2-b1802af9cc93"
      },
      "outputs": [],
      "source": [
        "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달\n",
        "# 이를 통해 AI 모델이 생성한 메시지를 반환\n",
        "chain.invoke(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAglQhBtvPJg",
        "outputId": "0a0e914a-e985-4c53-961f-b1c0d97ea854"
      },
      "outputs": [],
      "source": [
        "# 스트리밍 출력을 위한 요청\n",
        "answer = chain.stream(input)\n",
        "# 스트리밍 출력\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKNEOwk_vPJg"
      },
      "source": [
        "### 출력파서(Output Parser)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3STad1bNvPJg"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OT6cZXCvPJg",
        "outputId": "0143095c-2271-4a71-c25f-4fd0bf8be72d"
      },
      "outputs": [],
      "source": [
        "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
        "chain = prompt | model | output_parser\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "k4pCMXZgvPJg",
        "outputId": "1e8b9433-88e9-4564-a506-1b8d2d1c3fa1"
      },
      "outputs": [],
      "source": [
        "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
        "input = {\"topic\": \"인공지능의 학습 원리\"}\n",
        "chain.invoke(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbQx9JyQvPJg",
        "outputId": "2da6ef49-cdcb-427d-e441-2318b4969ef7"
      },
      "outputs": [],
      "source": [
        "# 스트리밍 출력을 위한 요청\n",
        "answer = chain.stream(input)\n",
        "# 스트리밍 출력\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [실습] 최종! 셰프 챗봇을 실행해보기\n",
        "\n",
        "- 마지막 StrOutputParser()까지 추가하여 `chef_chain` 완성하기\n",
        "- 변수 `food_input`에 딕셔너리 형태로 재료 넣어 `chef_chain` 실행해보기\n",
        "- Ex) 두부, 김치, 당근 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTpjg46svPJg"
      },
      "source": [
        "### 템플릿을 변경하여 적용\n",
        "\n",
        "- 아래의 프롬프트 내용을 얼마든지 **변경** 가능\n",
        "- `model_name` 역시 변경하여 테스트가 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PvH_BbOVvPJg"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 맞는 영어 회화를 작성해 주세요.\n",
        "양식은 [FORMAT]을 참고하여 작성해 주세요.\n",
        "\n",
        "#상황:\n",
        "{question}\n",
        "\n",
        "#FORMAT:\n",
        "- 영어 회화:\n",
        "- 한글 해석:\n",
        "\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿을 이용하여 프롬프트를 생성\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# ChatOpenAI 챗모델을 초기화\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
        "\n",
        "# 문자열 출력 파서를 초기화\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cA9OKXLKvPJg"
      },
      "outputs": [],
      "source": [
        "# 체인을 구성\n",
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lt5bPABvPJg",
        "outputId": "8197e685-009f-4967-bdc4-285788236488"
      },
      "outputs": [],
      "source": [
        "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
        "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_OIYNw1vPJg",
        "outputId": "64f1ffe6-be41-4f2d-cb8c-87ff86b102f7"
      },
      "outputs": [],
      "source": [
        "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
        "# 스트리밍 출력을 위한 요청\n",
        "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
        "# 스트리밍 출력\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dinebuFhvPJh",
        "outputId": "a3340519-9dde-4c5d-d8dc-ef3ff2941822"
      },
      "outputs": [],
      "source": [
        "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
        "# 스트리밍 출력을 위한 요청\n",
        "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
        "# 스트리밍 출력\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoFhXhgBvPJh"
      },
      "source": [
        "### [실습] 템플릿을 변경하여 나만의 여행 가이드 챗봇 만들기\n",
        "\n",
        "- 위의 프롬프트를 아래 주제에 맞게 **변경** 해보기\n",
        "1. 페르소나: 10년차 여행 가이드\n",
        "2. 3일간 가성비 여행 계획을 세워주는 챗봇 생성\n",
        "3. `{question}` 에는 여행갈 나라와 도시를 사용자에게 입력받음\n",
        "4. `answer` 변수를 출력하여 챗봇의 답변 결과 확인\n",
        "5. `Langsmith` 에 접속하여 실행 내용 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "oFnuVWIQvPJh",
        "outputId": "bcf4b934-8c14-4941-830f-dd7d92d132fa"
      },
      "outputs": [],
      "source": [
        "tour_guide_template = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿을 이용하여 프롬프트를 생성\n",
        "prompt = PromptTemplate.from_template( )\n",
        "\n",
        "# ChatOpenAI 챗모델을 초기화\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
        "\n",
        "# 문자열 출력 파서를 초기화\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 체인을 구성\n",
        "chain = ----- | ---- | ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGS2ITLEvPJh"
      },
      "outputs": [],
      "source": [
        "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
        "# 스트리밍 출력을 위한 요청\n",
        "answer = chain.stream({\"question\": \"저는 대한민국 서울을 여행하고 싶습니다.\"})\n",
        "# 스트리밍 출력\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16DBUP_9vPJh"
      },
      "outputs": [],
      "source": [
        "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
        "# 스트리밍 출력을 위한 요청\n",
        "answer = chain.stream({\"question\": \"저는 이탈리아 로마를 여행하고 싶습니다.\"})\n",
        "# 스트리밍 출력\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDSJ-la9y7XP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
